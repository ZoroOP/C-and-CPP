{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Python-中文编码\" data-toc-modified-id=\"Python-中文编码-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Python 中文编码 </a></div><div class=\"lev2 toc-item\"><a href=\"#字符串和编码\" data-toc-modified-id=\"字符串和编码-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>字符串和编码 </a></div><div class=\"lev2 toc-item\"><a href=\"#存储和执行时的状态\" data-toc-modified-id=\"存储和执行时的状态-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>存储和执行时的状态 </a></div><div class=\"lev2 toc-item\"><a href=\"#Python-字符串\" data-toc-modified-id=\"Python-字符串-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Python 字符串</a></div><div class=\"lev3 toc-item\"><a href=\"#encode\" data-toc-modified-id=\"encode-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span><code>encode</code></a></div><div class=\"lev3 toc-item\"><a href=\"#decode\" data-toc-modified-id=\"decode-132\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span><code>decode</code></a></div><div class=\"lev3 toc-item\"><a href=\"#str\" data-toc-modified-id=\"str-133\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span><code>str</code></a></div><div class=\"lev3 toc-item\"><a href=\"#type\" data-toc-modified-id=\"type-134\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span><code>type</code></a></div><div class=\"lev1 toc-item\"><a href=\"#实际程序中的编码\" data-toc-modified-id=\"实际程序中的编码-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>实际程序中的编码</a></div><div class=\"lev2 toc-item\"><a href=\"#Python-源代码中的说明\" data-toc-modified-id=\"Python-源代码中的说明-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Python 源代码中的说明</a></div><div class=\"lev2 toc-item\"><a href=\"#要循环处理字符串的时候需要解码\" data-toc-modified-id=\"要循环处理字符串的时候需要解码-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>要循环处理字符串的时候需要解码</a></div><div class=\"lev2 toc-item\"><a href=\"#字符匹配的时候需要解码\" data-toc-modified-id=\"字符匹配的时候需要解码-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>字符匹配的时候需要解码</a></div><div class=\"lev2 toc-item\"><a href=\"#结巴分词\" data-toc-modified-id=\"结巴分词-24\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>结巴分词</a></div><div class=\"lev3 toc-item\"><a href=\"#jieba-分词后词语变为-unicode-编码\" data-toc-modified-id=\"jieba-分词后词语变为-unicode-编码-241\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>jieba 分词后词语变为 unicode 编码</a></div><div class=\"lev3 toc-item\"><a href=\"#去掉标点符号\" data-toc-modified-id=\"去掉标点符号-242\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>去掉标点符号</a></div><div class=\"lev1 toc-item\"><a href=\"#读存文档时的编码\" data-toc-modified-id=\"读存文档时的编码-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>读存文档时的编码</a></div><div class=\"lev2 toc-item\"><a href=\"#读取文档注意事项\" data-toc-modified-id=\"读取文档注意事项-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>读取文档注意事项</a></div><div class=\"lev2 toc-item\"><a href=\"#txt-文档\" data-toc-modified-id=\"txt-文档-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>txt 文档</a></div><div class=\"lev2 toc-item\"><a href=\"#codecs\" data-toc-modified-id=\"codecs-33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span><code>codecs</code></a></div><div class=\"lev2 toc-item\"><a href=\"#JSON\" data-toc-modified-id=\"JSON-34\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span><code>JSON</code></a></div><div class=\"lev2 toc-item\"><a href=\"#直接存储-Unicode\" data-toc-modified-id=\"直接存储-Unicode-35\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>直接存储 Unicode</a></div><div class=\"lev2 toc-item\"><a href=\"#直接存储-String\" data-toc-modified-id=\"直接存储-String-36\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>直接存储 String</a></div><div class=\"lev1 toc-item\"><a href=\"#参考资料\" data-toc-modified-id=\"参考资料-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>参考资料</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 中文编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 中文编码是新人常见的一个问题，其实这是一个涉及到 Python 字符串、编码、IO 读写等方面的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字符串和编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算机只能处理数字，文本需要转为数字。最早的计算机采用 8 个 bit（比特，计算机最小数据单位） 作为一个 byte（字节，存储和传输容量的一种基本计量单位）。所以一个字节表示的最大整数是 255（二进制：11111111 = 十进制 255：2^7 + 2^6 +...+ 2^1 +2^0），更大整数需要更多字节。\n",
    "\n",
    "最早只有 127 个字母（英文的大小写字母和数字，一些符号等）被编码到计算机，这个编码表就是 `ASCII`，没有中文。  \n",
    "中文至少需要两个字节，并且不能和已有的 `ASCII` 冲突，于是有了中国制定的 `GB2312` 编码，用来把中文编进去。  \n",
    "\n",
    "全世界很多语言，就会有很多编码，因此 `Unicode` 就出现了，从字面意思也可以看出这是一套“整合”的编码。不过由于中文等语言编码长度很长，就会导致只使用英文的文本多占用很多存储空间，在存储和传输上十分不方便。于是，出现了把 Unicode 转化为“可变长编码”的 `UTF-8` 编码。\n",
    "\n",
    "`UTF-8` 编码把一个 Unicode 字符根据不同的数字大小编码成 1-6 个字节：  \n",
    "- 英文字母 1 个字节\n",
    "- 汉字通常 3 个字节\n",
    "这样，无论传输什么文本，`UTF-8` 都能节省空间。总结下就是，`ASCII` 实际可以看成是 `UTF-8` 的一部分，所以之前的软件现在也能使用，这个也可以看作是一种向下兼容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 存储和执行时的状态"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在计算机内存中，统一使用 Unicode 编码；当需要保存到硬盘，或者在网络上传输时，就转为 UTF-8 编码  \n",
    "\n",
    "记事本编辑时，从文件读取的 UTF-8 字符被转为 Unicode 字符到内存里；编辑完成保存时，把 Unicode 转换为 UTF-8 保存  \n",
    "\n",
    "浏览网页时，服务器会把生成的 Unicode 转换为 UTF-8 再传输导浏览器，所以很多网页是用 UTF-8 编码的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 诞生早于 Unicode 标准发布，所以最早只支持 ASCII 编码（不支持中文），后来增加了对 Unicode 的编码，就是看到的 `u'...'`，就表示是用 Unicode 编码的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中文\n"
     ]
    }
   ],
   "source": [
    "print u'中文'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\u4e2d'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u'中'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'A'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'A'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u'\\u0041'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`u'中'` 和 `u'\\u4e2d'` 一致，`\\u` 后面是十六进制的 Unicode 码。  \n",
    "\n",
    "对英文来说，字符串 `'xxx'` 可以看作是 ASCII 编码，也可以看作是 UTF-8 编码，但是 `u'xxx'` 一定是 Unicode 编码  \n",
    "\n",
    "Unicode 转换为 UTF-8 用 encode，相反则用 decode：  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `encode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABC'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u'ABC'.encode('utf-8') # 没变化，但占用的存储空间不同，UTF-8 占用的少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xe4\\xb8\\xad\\xe6\\x96\\x87'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u'中文'.encode('utf-8') # 1 个 Unicode 的汉字转为 3 个字节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u'ABC'), len('ABC') # 长度一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u'中文'), len(u'中文'.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `decode`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`decode` 可以把 UTF-8 表示的字符串转换为 Unicode 字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'abc'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'abc'.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\u4e2d\\u6587'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\\xe4\\xb8\\xad\\xe6\\x96\\x87'.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中文\n"
     ]
    }
   ],
   "source": [
    "print '\\xe4\\xb8\\xad\\xe6\\x96\\x87'.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `str`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用 str 也可以把 unicode 重新编码 utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xe4\\xb8\\xad\\xe6\\x96\\x87'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*- \n",
    "\n",
    "str('中文')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xe4\\xb8\\xad\\xe6\\x96\\x87'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str('\\xe4\\xb8\\xad\\xe6\\x96\\x87')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(u'中文')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type('中文') # 中文字符串是 UTF-8 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xe4\\xb8\\xad\\xe6\\x96\\x87'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'中文'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type('\\xe4\\xb8\\xad\\xe6\\x96\\x87'.decode('utf-8')) # UTF-8 码转为 Unicode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实际程序中的编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 源代码中的说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在保存源代码时要声明程序的编码类型为 utf-8，这样当 Python 解释器去读取源代码时就会明白：\n",
    "\n",
    "- `!/usr/bin/env python2.7`  \n",
    "- `-*- coding: utf-8 -*-`  \n",
    "\n",
    "第一行告诉 Linux/OS X 这是一个 Python 可执行程序  \n",
    "第二行告诉 Python 解释器，按照 UTF-8 读取源代码，否则源代码中的中文可能会乱码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 要循环处理字符串的时候需要解码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�\n",
      "�\n",
      "�\n",
      ".\n",
      "!\n",
      "?\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      ":\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*- \n",
    "\n",
    "token = \"，.!?？：:\"\n",
    "\n",
    "for t in token:\n",
    "    print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "，\n",
      ".\n",
      "!\n",
      "?\n",
      "？\n",
      "：\n",
      ":\n"
     ]
    }
   ],
   "source": [
    "# 解码\n",
    "for t in token.decode('utf-8'):\n",
    "    print t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把字符串 decode 为 utf-8 后，就可以被遍历**循环**了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字符匹配的时候需要解码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evil_rabbit/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:10: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*- \n",
    "\n",
    "token = \"，。！？：；\".decode('utf8')\n",
    "string_list = ['我', '是', '中国', '人' ,'，', '我', '爱', '她', '。']\n",
    "\n",
    "for t in token:\n",
    "    \n",
    "    for s1 in string_list:\n",
    "        \n",
    "        if t == s1: # 逗号和句号无法匹配的，因为编码不同\n",
    "            print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "，\n",
      "。\n"
     ]
    }
   ],
   "source": [
    "for t in token:\n",
    "    \n",
    "    for s1 in string_list:\n",
    "        \n",
    "        if t == s1.decode('utf-8'): # 编码相同，可以匹配；UTF-8 转为 Unicode\n",
    "            print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xe6\\x88\\x91'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'我'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "，\n",
      "。\n"
     ]
    }
   ],
   "source": [
    "for t in token:\n",
    "    \n",
    "    for s1 in string_list:\n",
    "        \n",
    "        if t.encode('utf-8') == s1: # 编码相同，可以匹配\n",
    "            print t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结巴分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jieba 分词后词语变为 unicode 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'\\u6211', u'\\u662f', u'\\u4e2d\\u56fd', u'\\u4eba', u'\\uff0c', u'\\u6211', u'\\u559c\\u6b22', u'\\u7f16\\u7a0b', u'\\u3001', u'\\u97f3\\u4e50', u'\\u3001', u'\\u8fd0\\u52a8', u'\\u3001', u'\\u770b\\u4e66', u'\\u3002']\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*- \n",
    "\n",
    "import jieba\n",
    "\n",
    "string = \"我是中国人，我喜欢编程、音乐、运动、看书。\"\n",
    "\n",
    "string_list = []\n",
    "\n",
    "seg = jieba.cut(string)\n",
    "\n",
    "for word in seg:\n",
    "    string_list.append(word)\n",
    "\n",
    "print string_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去掉标点符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我\n",
      "是\n",
      "中国\n",
      "人\n",
      "我\n",
      "喜欢\n",
      "编程\n",
      "音乐\n",
      "运动\n",
      "看书\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*- \n",
    "\n",
    "import jieba\n",
    "\n",
    "string = \"我是中国人，我喜欢编程、音乐、运动、看书。\"\n",
    "\n",
    "string_list = []\n",
    "\n",
    "seg = jieba.cut(string)\n",
    "\n",
    "for i in seg:\n",
    "    string_list.append(i)\n",
    "\n",
    "token = \"，。！？：；、\".decode('utf-8')\n",
    "\n",
    "filter_seg = [fil for fil in string_list if fil not in token]\n",
    "\n",
    "for word in filter_seg:\n",
    "    \n",
    "    print word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我\n",
      "是\n",
      "中国\n",
      "人\n",
      "我\n",
      "喜欢\n",
      "编程\n",
      "音乐\n",
      "运动\n",
      "看书\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*- \n",
    "\n",
    "import jieba\n",
    "\n",
    "string = \"我是中国人，我喜欢编程、音乐、运动、看书。\"\n",
    "\n",
    "string_list = []\n",
    "\n",
    "seg = jieba.cut(string)\n",
    "\n",
    "for i in seg:\n",
    "    string_list.append(i)\n",
    "\n",
    "token = \"，。！？：；、\".decode('utf-8')\n",
    "\n",
    "for word in string_list:\n",
    "    \n",
    "    if word not in token:\n",
    "        print word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读存文档时的编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取文档注意事项"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了避免每次都要 close 文件，建议使用 with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/./xx.txt', 'r') as f:\n",
    "    f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read()` 会一次性读取全部内容，如果文件太大，可以用 `read(size)` 读取 size 个字节的内容。  \n",
    "或者调用 `readline()` 按行读取；调用 `readlines()` 一次读取所有内容并按行返回 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in f.readlines():\n",
    "    line.strip() # 去掉末尾的 '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## txt 文档"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- txt 文档存储时要另存为 utf-8 编码。txt 文档默认编码为 ascii\n",
    "- 列表内容存储回 txt 文档时，要把 Python 里的 unicode 编码为 utf-8。只有编码为 utf-8，才能正常在 txt 文档中显示出来  \n",
    "\n",
    "  - `encode('utf-8')`\n",
    "  - str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*- \n",
    "\n",
    "import jieba\n",
    "\n",
    "string = \"我是中国人，我喜欢编程、音乐、运动、看书。\"\n",
    "\n",
    "string_list = []\n",
    "\n",
    "seg = jieba.cut(string)\n",
    "\n",
    "for i in seg:\n",
    "    string_list.append(i)\n",
    "\n",
    "token = \"，。！？：；、\".decode('utf-8') # 对 UTF-8 的字符串解为 Unicode\n",
    "\n",
    "filter_seg = [fil for fil in string_list if fil not in token]\n",
    "\n",
    "f = open('output.txt', 'w')\n",
    "\n",
    "for word in filter_seg:\n",
    "    f.write(word.encode('utf-8') + ' ')\n",
    "    #f.write(str(word)+' ') # 不成功，采用 encode\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果读取非 ASCII 编码的文本文件，可以用二进制模式打开，再解码；或者给 `open` 函数传入 `encoing` 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBK 编码的文件\n",
    "f = open('./xx.txt', 'rb') # 二进制读取\n",
    "u = f.read().decode('gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('/./xx.txt', 'r', encoding='gbk')\n",
    "f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遇到编码不规范的文件，可以给 `open` 函数一个 `errors` 的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('/./xx.txt', 'r', encoding='gbk', errors='ignore') # 忽略错误编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `codecs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python 的 `codecs` 模块可以帮助我们在读取文件时自动转换编码，直接读出 Unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GBK 编码的文件\n",
    "import codecs\n",
    "with codecs.open('/./xx.txt', 'r', 'gbk') as f:\n",
    "    f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `JSON`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON 是不同语言的标准格式，速度快，而且可以直接在 Web 页面读取，非常方便。  \n",
    "因此，我们可以将一些需要调取的 dict 存储为 JSON。  \n",
    "另外一个原因，JSON 标准规定编码是 UTF-8，所以 Python 内置的 `json` 模块让我们很方便地在 Python 的 `str` 与 JSON 字符串之间转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"age\": 20, \"score\": 88, \"name\": \"Bob\"}'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "d = dict(name='Bob', age=20, score=88)\n",
    "json.dumps(d) # dumps 返回一个 str，内容就是标准的 JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'age': 20, u'name': u'Bob', u'score': 88}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_str = '{\"age\": 20, \"score\": 88, \"name\": \"Bob\"}'\n",
    "json.loads(json_str) # 成功读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实际操作中，可以直接将 `json.dumps(d)` 写入 txt 文档，读取时 `json.loads(f.read())` 即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直接存储 Unicode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不将 Unicode 转为实际的文本存储字符集，而是将 Unicode 的内存编码值直接存储，读取文件时再反向转换回来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\u4e2d\\\\u6587'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 存储\n",
    "# 从 Unicode 到 Unicode-escape\n",
    "# unicodestr.encode('unicode-escape')\n",
    "u'中文'.encode('unicode-escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\u4e2d\\u6587'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取\n",
    "# 从 Unicode-escape 到 Unicode\n",
    "# unicodestr.decode('unicode-escape')\n",
    "'\\\\u4e2d\\\\u6587'.decode('unicode-escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中文\n"
     ]
    }
   ],
   "source": [
    "print(u'\\u4e2d\\u6587')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直接存储 String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于 UTF-8 编码的字符串，在存储时也可以直接存储编码值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\xe4\\\\xb8\\\\xad\\\\xe6\\\\x96\\\\x87'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 存储\n",
    "# 从 UTF-8 到 string-escape\n",
    "# utf8str.encode('string-escape')\n",
    "'中文'.encode('string-escape')# 注意 '中文' 是 UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xe4\\xb8\\xad\\xe6\\x96\\x87'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取\n",
    "# 从 string-escape 到 UTF-8\n",
    "# utf8str.decode('string-escape')\n",
    "'\\\\xe4\\\\xb8\\\\xad\\\\xe6\\\\x96\\\\x87'.decode('string-escape')# 注意 string '中文' 是 UTF-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考资料\n",
    "\n",
    "- [python 的中文编码_乱码问题的解决方法和探寻](http://blog.sina.com.cn/s/blog_6285b6f60100u15a.html)  \n",
    "- [初探 python 编码](http://blog.csdn.net/liuxincumt/article/details/8183391)\n",
    "- [廖雪峰 Python 教程](http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000)\n",
    "- [Python 中 Unicode 字符串](http://bbs.csdn.net/topics/390388139)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "0px",
    "width": "0px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
